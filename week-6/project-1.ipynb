{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object detection using YOLOv3 on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net =  cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "classes = []\n",
    "with open('cfg/coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Load input video\n",
    "video_file = 'vid/vid_1.mp4'\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Object Detection Loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Preprocess input image\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "    # Process detection results\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Non-max suppression to remove redundant overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 11:24:26.227 Python[8909:363288] +[CATransaction synchronize] called within transaction\n",
      "2024-04-24 11:24:26.387 Python[8909:363288] +[CATransaction synchronize] called within transaction\n",
      "2024-04-24 11:24:26.396 Python[8909:363288] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ObjectDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Object Detection App\")\n",
    "        self.root.geometry(\"400x300\")\n",
    "\n",
    "        # Create title label\n",
    "        title_label = tk.Label(self.root, text=\"Object Detection App\", font=(\"Helvetica\", 16, \"bold\"), pady=10)\n",
    "        title_label.pack()\n",
    "\n",
    "        # Create buttons frame\n",
    "        buttons_frame = tk.Frame(self.root)\n",
    "        buttons_frame.pack(pady=10)\n",
    "\n",
    "        # Create buttons\n",
    "        self.select_button = tk.Button(buttons_frame, text=\"Select Video\", command=self.select_video)\n",
    "        self.select_button.grid(row=0, column=0, padx=10)\n",
    "\n",
    "        self.play_button = tk.Button(buttons_frame, text=\"Play Video\", command=self.play_video)\n",
    "        self.play_button.grid(row=0, column=1, padx=10)\n",
    "\n",
    "        self.detect_button = tk.Button(buttons_frame, text=\"Detect Objects\", command=self.detect_objects)\n",
    "        self.detect_button.grid(row=1, column=0, columnspan=2, pady=10)\n",
    "\n",
    "        self.exit_button = tk.Button(self.root, text=\"Exit\", command=self.root.quit)\n",
    "        self.exit_button.pack()\n",
    "\n",
    "        # Video capture object\n",
    "        self.cap = None\n",
    "\n",
    "    def select_video(self):\n",
    "        # Open file dialog to select video file\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4\")])\n",
    "        if file_path:\n",
    "            # Release any existing video capture object\n",
    "            if self.cap:\n",
    "                self.cap.release()\n",
    "            # Create new video capture object\n",
    "            self.cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    def play_video(self):\n",
    "        if self.cap:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                cv2.imshow(\"Video\", frame)\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        if self.cap:\n",
    "            net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "            classes = []\n",
    "            with open('cfg/coco.names', 'r') as f:\n",
    "                classes = f.read().splitlines()\n",
    "\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                height, width, _ = frame.shape\n",
    "                blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "                net.setInput(blob)\n",
    "                output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "                layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "                boxes = []\n",
    "                confidences = []\n",
    "                class_ids = []\n",
    "\n",
    "                for output in layer_outputs:\n",
    "                    for detection in output:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.5:\n",
    "                            center_x = int(detection[0] * width)\n",
    "                            center_y = int(detection[1] * height)\n",
    "                            w = int(detection[2] * width)\n",
    "                            h = int(detection[3] * height)\n",
    "\n",
    "                            x = int(center_x - w/2)\n",
    "                            y = int(center_y - h/2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(classes[class_ids[i]])\n",
    "                        confidence = str(round(confidences[i], 2))\n",
    "                        color = colors[i]\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                        cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "                cv2.imshow(\"Object Detection\", frame)\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ObjectDetectionApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
