{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e870781f-2b60-45c7-a7f3-bec661bdbb12",
   "metadata": {},
   "source": [
    "#### Practice 3: YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170d4b3a-5704-46a9-99ec-84a428139aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.381] global loadsave.cpp:248 findDecoder imread_('images/lake.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load input image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/lake.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Preprocess input image\u001b[39;00m\n\u001b[1;32m     15\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(image, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m, (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net =  cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "classes = []\n",
    "with open('cfg/coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Load input image\n",
    "image = cv2.imread('images/lake.jpg')\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Preprocess input image\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "\n",
    "# Forward pass through the network\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "\n",
    "# Forward pass through network\n",
    "output_layers_names = net.getUnconnectedOutputLayersNames()\n",
    "layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "# Process detection results\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "\n",
    "for output in layer_outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Non-max suppression to remove redundant overlapping boxes\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Draw bounding boxes and labels\n",
    "for i in indexes.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(image, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc559d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
